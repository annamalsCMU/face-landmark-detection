{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 400000, 23876)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "len(os.listdir('faces_data/test')), \\\n",
    "len(os.listdir('faces_data/train')), \\\n",
    "len(os.listdir('faces_data/val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### flm_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "from code.utils.GenUtils import GenUtils\n",
    "from code.utils.ImageUtils import ImageUtils\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, model_from_json, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow import keras\n",
    "\n",
    "class FaceLandmarkDetection:\n",
    "    def __init__(self):\n",
    "        self.genu = GenUtils()\n",
    "        # print(self.genu)\n",
    "        self.imu = ImageUtils()\n",
    "        pass\n",
    "\n",
    "    def getDataPaths(self, path, dir):\n",
    "        img_files = glob(os.path.join(path,dir, \"*.jpg\"))\n",
    "        ann_files = glob(os.path.join(path,dir, \"*.pkl\"))\n",
    "        assert(len(img_files) == len(ann_files)), \"#Images != #Annotations\"\n",
    "        return list(zip(img_files, ann_files))\n",
    "\n",
    "    def data_generator(self, data, batch_size=32, shuffle_data=True):\n",
    "        tot_len = len(data)\n",
    "\n",
    "        while True:\n",
    "            if shuffle_data:\n",
    "                random.shuffle(data)\n",
    "\n",
    "            for offset in range(0, tot_len, batch_size):\n",
    "                thisBatch = data[offset:offset+batch_size]\n",
    "                X, y = [], []\n",
    "                for img_path, annot_path in thisBatch:\n",
    "                    im = cv2.imread(img_path)\n",
    "                    annot = self.genu.loadPKL(annot_path)\n",
    "                    X.append(im / 255.) # normalize\n",
    "                    y.append(annot)\n",
    "                X = np.stack(X)\n",
    "                y = np.stack(y)\n",
    "\n",
    "                yield X, y\n",
    "\n",
    "    def FLMmodel(self, ip_dims, op_units):\n",
    "        # Approaching Human level facial landmark localization paper\n",
    "        # based architecture\n",
    "\n",
    "        i = Input(shape=ip_dims)\n",
    "\n",
    "        x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(i)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D()(x)\n",
    "\n",
    "        x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D()(x)\n",
    "\n",
    "        x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D()(x)\n",
    "\n",
    "        x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D()(x)\n",
    "\n",
    "        x = Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(units=512, activation='relu')(x)\n",
    "        x = Dense(units=op_units, activation='sigmoid')(x)\n",
    "\n",
    "        model = Model(i, x)\n",
    "        print(model.summary())\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, X_dims, y_dim, train_files, val_files,\n",
    "              epochs, batch_size, lr,\n",
    "              model_path, model_prefix,\n",
    "              display=True):\n",
    "\n",
    "        self.model = self.FLMmodel(X_dims, y_dim)\n",
    "\n",
    "        self.model.compile(optimizer=Adam(lr=lr),\n",
    "                           loss=keras.losses.mean_squared_error,\n",
    "                           metrics=[keras.metrics.mean_squared_error])\n",
    "\n",
    "        model_nm = \"_\".join([model_prefix, \"FLMmodel_Wgts\",\n",
    "                    str(epochs), str(batch_size), str(lr)])+\".h5\"\n",
    "        arch_nm = \"_\".join([model_prefix, \"FLMmodel_Arch\",\n",
    "                    str(epochs), str(batch_size), str(lr)])+\".txt\"\n",
    "\n",
    "        checkpoints = ModelCheckpoint(os.path.join(model_path, model_nm), monitor='val_loss',\n",
    "                                      verbose=1, save_best_only=True, mode='min')\n",
    "        callback_ls = [checkpoints]\n",
    "\n",
    "        # data generators and steps\n",
    "        train_batch_size = len(train_files) if len(train_files) < batch_size else batch_size\n",
    "        train_gen = self.data_generator(train_files, batch_size=train_batch_size, shuffle_data=True)\n",
    "\n",
    "        val_batch_size = len(val_files) if len(val_files) < batch_size else batch_size\n",
    "        val_gen = self.data_generator(val_files, batch_size=val_batch_size, shuffle_data=True)\n",
    "\n",
    "        steps_per_epoch = len(train_files) // batch_size\n",
    "        val_steps = len(val_files) // batch_size\n",
    "\n",
    "        # train\n",
    "        r = self.model.fit(train_gen,\n",
    "                           epochs=epochs,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           validation_data=val_gen,\n",
    "                           validation_steps=val_steps,\n",
    "                           callbacks=callback_ls,\n",
    "                           verbose=1)\n",
    "\n",
    "        # display loss accuracy\n",
    "        if display:\n",
    "            plt.plot(r.history[\"loss\"], label=\"loss\")\n",
    "            plt.plot(r.history[\"val_loss\"], label=\"val_loss\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        # save model architecture\n",
    "        with open(os.path.join(model_path, arch_nm), 'w',\n",
    "                  encoding='utf-8') as arch:\n",
    "            json.dump(self.model.to_json(), arch)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def loadModel(self, model_path, arch_nm, model_nm):\n",
    "        with open(os.path.join(model_path, arch_nm), 'r',\n",
    "                  encoding='utf-8') as json_file:\n",
    "            arch = json.load(json_file)\n",
    "\n",
    "        # load architecture\n",
    "        self.model = model_from_json(arch)\n",
    "        # load weights\n",
    "        self.model.load_weights(os.path.join(model_path, model_nm))\n",
    "\n",
    "        # print(self.model.summary())\n",
    "        pass\n",
    "\n",
    "    def saveKerasModel(self, model_path, model_arch, model_weights, model_nm):\n",
    "        with open(os.path.join(model_path, model_arch), 'r',\n",
    "                  encoding='utf-8') as json_file:\n",
    "            arch = json.load(json_file)\n",
    "\n",
    "        # load architecture\n",
    "        model = model_from_json(arch)\n",
    "        # load weights\n",
    "        model.load_weights(os.path.join(model_path, model_weights))\n",
    "\n",
    "        model.save(os.path.join(model_path, model_nm))\n",
    "        print(f\"Saved successfully in {model_path} as {model_nm}\")\n",
    "\n",
    "    def loadKerasModel(self, model_path, model_nm):\n",
    "        self.model = load_model(os.path.join(model_path, model_nm))\n",
    "        pass\n",
    "\n",
    "    def predict_one(self, x):\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        y_pred = self.model.predict(x)\n",
    "        return y_pred\n",
    "\n",
    "    def predict_datagen(self, data, model_path=\"\", prefix=\"\", savePreds=True):\n",
    "        if len(data) == 0:\n",
    "            print(\"No data to feed test generator\")\n",
    "            return None, None\n",
    "\n",
    "        test_gen = self.data_generator(data, batch_size=1, shuffle_data=False)\n",
    "        preds = self.model.predict(test_gen, steps=len(data))\n",
    "\n",
    "        if savePreds:\n",
    "            print(\"saving the predictions matrix....\")\n",
    "            pred_filename = f\"{prefix}_pred_matrix\"\n",
    "            self.genu.dumpPKL(preds, model_path, pred_filename)\n",
    "            print(f\"predictions saved in {model_path} with the name {pred_filename}\")\n",
    "\n",
    "        return preds, self.score(data, preds)\n",
    "\n",
    "\n",
    "    def score(self, actuals_path, preds):\n",
    "        y = self.genu.getActualsFromPKLs(actuals_path)\n",
    "        rmse = (np.sqrt(np.square(y - preds))).mean(axis=0)\n",
    "        avg_rmse = rmse.mean()\n",
    "        return avg_rmse\n",
    "\n",
    "    # def testImages(self, X, y, name, w, h):\n",
    "    #     idx = np.random.choice(y.shape[0])\n",
    "    #     y = y[idx].reshape(-1, 2)\n",
    "    #     y = self.imu.getInvTransformCoords(y, w, h)\n",
    "    #     self.imu.drawAnnotationsOnImg(X[idx], y, window=name, display=True)\n",
    "    #     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# from code.flm_detection_model.flm_model import FaceLandmarkDetection\n",
    "from code.utils.GenUtils import GenUtils\n",
    "from code.utils.ImageUtils import ImageUtils\n",
    "\n",
    "def train(data_path, model_path, model_prefix,\n",
    "          h, w, c, l, epochs, lr, batch_size):\n",
    "    flm = FaceLandmarkDetection()\n",
    "\n",
    "#     train_files = flm.getDataPaths(data_path, \"train\")\n",
    "#     val_files = flm.getDataPaths(data_path, \"val\")\n",
    "\n",
    "    # train and save best model\n",
    "#     flm.train(X_dims=(h, w, c),\n",
    "#               y_dim=l*2,\n",
    "#               train_files=train_files,\n",
    "#               val_files=val_files,\n",
    "#               epochs=epochs,\n",
    "#               batch_size=batch_size,\n",
    "#               lr=lr,\n",
    "#               model_path=model_path,\n",
    "#               model_prefix=model_prefix,\n",
    "#               display=True)\n",
    "    \n",
    "    # save the keras model\n",
    "    flm.saveKerasModel(model_path=model_path, \n",
    "                     model_weights=f\"{model_prefix}_FLMmodel_Wgts_{epochs}_{batch_size}_{lr}.h5\",\n",
    "                     model_arch=f\"{model_prefix}_FLMmodel_Arch_{epochs}_{batch_size}_{lr}.txt\",\n",
    "                     model_nm=f\"{model_prefix.upper()}_FLMmodel_{epochs}_{batch_size}_{lr}.h5\")\n",
    "\n",
    "# load saved model\n",
    "def getPredictionsAndScore(data_path, model_path, model_prefix,\n",
    "                           model_nm):\n",
    "    flm = FaceLandmarkDetection()\n",
    "#     flm.loadModel(model_path=model_path,\n",
    "#                   arch_nm=arch_nm,\n",
    "#                   model_nm=model_nm)\n",
    "    flm.loadKerasModel(model_path=model_path, model_nm=model_nm)\n",
    "    \n",
    "    test_files = flm.getDataPaths(data_path, \"test\")\n",
    "    print(\"Predicting test_files ....\")\n",
    "    preds, score = flm.predict_datagen(data=test_files,\n",
    "                               model_path=model_path,\n",
    "                               prefix=model_prefix)\n",
    "    print(\"-\"*30)\n",
    "    print(\"average RMSE:\")\n",
    "    print(score)\n",
    "    print(\"-\" * 30)\n",
    "    return preds, score\n",
    "\n",
    "def showPredicitons(data_path, model_path, pred_name, w, h):\n",
    "    flm = FaceLandmarkDetection()\n",
    "    test_files = flm.getDataPaths(data_path, \"test\")\n",
    "    genu = GenUtils()\n",
    "    imu = ImageUtils()\n",
    "    preds = genu.loadPKL(os.path.join(model_path,pred_name))\n",
    "    print(preds)\n",
    "\n",
    "    while True:\n",
    "        X = [ (\n",
    "                imu.drawAnnotationsOnImg(\n",
    "                        test_files[idx][0],\n",
    "                        imu.getInvTransformCoords(preds[idx].reshape(-1, 2), w, h),\n",
    "                        window=\"Preview\", display=False\n",
    "                    ),\n",
    "                str(idx)+\" || \"+test_files[idx][0].split(\"\\\\\")[-1]\n",
    "                )\n",
    "             for idx in np.random.choice(preds.shape[0], 1)]\n",
    "\n",
    "        imu.display_multiple_img([x[0] for x in X],\n",
    "                                 titles=[x[1] for x in X],\n",
    "                                 print_title=True,\n",
    "                                 rows=4, cols=5, window_size=(15,8))\n",
    "        ip = input(\"Continue? [Q/q to quit] / [other keys to continue]\")\n",
    "        if ip.lower() == 'q':\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully in code/flm_detection_model/model as GPU_RUN_2__FLMmodel_10_32_0.0001.h5\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Predicting test_files ....\n",
      "saving the predictions matrix....\n",
      "predictions saved in code/flm_detection_model/model with the name GPU_Run_2__pred_matrix\n",
      "------------------------------\n",
      "average RMSE:\n",
      "0.0063537699677548585\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_path = os.path.join(\"faces_data\")\n",
    "\n",
    "    model_path = os.path.join(\"code\", \"flm_detection_model\", \"model\")\n",
    "    model_prefix = \"GPU_Run_2_\"\n",
    "\n",
    "    HEIGHT = 128\n",
    "    WIDTH = 128\n",
    "    CHANNELS = 3\n",
    "    LANDMARKS = 68\n",
    "\n",
    "    epochs = 10\n",
    "    lr = 0.0001\n",
    "    batch_size = 32\n",
    "\n",
    "    train(data_path, model_path, model_prefix,\n",
    "          HEIGHT, WIDTH, CHANNELS, LANDMARKS, epochs, lr, batch_size)\n",
    "\n",
    "#   ##  see predictions\n",
    "    preds, score = getPredictionsAndScore(data_path=data_path,\n",
    "                                          model_path=model_path,\n",
    "                                          model_prefix=model_prefix,\n",
    "                                          model_nm=f\"{model_prefix.upper()}_FLMmodel_{epochs}_{batch_size}_{lr}.h5\",\n",
    "                                          )\n",
    "\n",
    "#     showPredicitons(data_path=data_path, model_path=model_path,\n",
    "#                     pred_name=f\"{model_prefix}_pred_matrix.pkl\",\n",
    "#                     w=WIDTH, h=HEIGHT)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
